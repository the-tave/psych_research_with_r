
```{r include=FALSE, warnings = FALSE}
seminar$soul_dummy <- ifelse(seminar$v11_soul == "yes", 1, 0)
```

# Difference Statistics

```{=html}
<script src="https://kit.fontawesome.com/0e67562c4f.js" crossorigin="anonymous"></script>
```

In this chapter, you will learn how to conduct some of the most common statistical analyses in R.
We will start with a re-cap of the statistics to get everyone on the same page, going over why the $\chi^2$ test, t-test and ANOVA are all in the same chapter and when to use each.
Then I want to mention some assumptions we have to check and lastly go over some examples fueled by students' ideas who attended my seminar that this work is based on. <i class="fa-regular fa-face-smile"></i>

## Statistics Re-cap <i class="fa-solid fa-graduation-cap" style="color: darkred;"></i>

Think about what do you remember from statistics and try to answer the two questions below: 

- What is Chi$^2$ / $\chi^2$?
- What is the t-test?
- What is an ANOVA?

What do they have in common?

`r hide()`

They measure _group differences_

`r unhide()`


What differentiates them?

`r hide()`

They are used for data of different scale levels

`r unhide()`
    
```{r echo = F, fig.height=3.5}
uni_colors <- usecol(pal = pal_unikn_ppt, n = 6)[1:3] # das trickst den Mechanismus aus, der da weiÃŸ reinknallt

ggplot(iris, aes(x = Species, y = Sepal.Length, color = Species, fill = Species)) +
  geom_boxplot(alpha = .6) +
  labs(Y = "Sepal Length", title = "Lengths of Flower Petals") +
  scale_color_manual(values = uni_colors) +
  scale_fill_manual(values = uni_colors) +
  theme_apa() +
  theme(legend.position = "none")

```

These three measures all provide us information on _differences_ either between naturally occurring groups (e.g. people of different genders) or between experimentally manipulated sub-samples (e.g. treatment vs. control group in a medical drug trial).^[You will usually see the $Chi^2$ test classified as an association statistic, which is technically more to the point. However, I like to think of it as quantifying differences between groups. After all, if you find systematic differences between groups in two given measures, that must mean that those measures are not independent, i.e. associated with each other.]

The $\chi^2$ statistic is commonly used on nominal data, e.g. if you want to compare proportions. 
Usually, the $\chi^2$ test is used with two binary variables, but it also works with more categories.
Considering the setup with the drug trials, we could check whether women and men received the drug and the placebo equally often.

With the t-Test it gets a bit trickier since there is more than one variant: Depending on the situation you can use the one-sample, two-sample or paired-samples t-test.
Generally speaking, you want to test one or two groups on a continuous attribute.

In the analysis of variance $\rightarrow$ _ANOVA_ you want to test three or more groups with one (or more) continuous attribute(s). 
I like to think of it as an augmentation of the t-test which takes into account some issues that we would face if we just used several t-tests in a setting with more than two groups (spoiler: It's called alpha-inflation and we do not want it).

This is a very basic overview of these tests, but it should give you a reminder if you have heard this before.
I will go over the purposes again as we look at the coding examples below.
If you think you might need a refresher on these stats that goes a little deeper, hop on over to the [Stats Picker](https://the-tave.shinyapps.io/Statistik-Picker) and to the Deep Dive tab.
There you will find some more information on multivariate statistics and how to use them. 

### Pre-Requisites

If you have been following along with the structure of this book, you will know what an R project is and that you were asked to create a folder called "data" in the according project folder in order to make the following command work to load the seminar data.
If you just want to access the tidily cleaned data directly, you can go to [the GitHub page](https://github.com/the-tave/psych_research_in_r/blob/main/data/seminar_data.Rds){target="_blank"} and download the datafile there.
Alternatively, there is a direct way to include data from GitHub in your script as long as you are connected to the internet, which you can find commented out below:

```{r eval = F}
seminar <- readRDS("./data/seminar_data.Rds")

# Access the data directly from GitHub
# seminar <- readRDS(gzcon(url("https://github.com/the-tave/psych_research_in_r/raw/main/data/seminar_data.Rds")))
```

Next, we will add a so-called _dummy-variable_ about believeing in the soul. 
It is not called "dummy" because we want to judge anybody's belief, but rather because it serves as a stand-in for a more complex variable, just like a test dummy is a stand-in for a real person.^[For more in-depth information on dummy variables you can visit: [https://stats.oarc.ucla.edu/wp-content/uploads/2016/02/p046.pdf](https://stats.oarc.ucla.edu/wp-content/uploads/2016/02/p046.pdf).]

Here, we basically want to create a dummy variable for believing in the soul where we summarize all those who said they don't know or they definitely don't believe into one category that we can later contrast with all those who said they do believe.
So in the new variable,  1 means _yes_ and 0 means _no or unsure_.

```{r eval=F}
seminar$soul_dummy <- ifelse(seminar$v11_soul == "yes", 1, 0)
```

### Statistical Significnace

In parametric statistics (which is the most common/basic kind), we make our test decision based on the distribution of out given test statistic.
This is because for any test statistic that we can calculate, we can make a prediction about its **distribution** if the true value were zero, i.e. no effect.
We would expected most values to fall in a certain range and if we find an empirical value (based on our data) that falls beyond that range, we conclude that it is so unlikely to find a value that extreme if we actually assume that range to be surrounding the true value.
We then conclude statistical significance because the empirical value of the test statistic is significantly different to the theoretical value distribution we would have if there were no true effect.

This measure of "how unlikely is our empirical value" is reflected in the **p-value**.
Commonly, we accept a threshold of $\alpha = .05$ as sufficiently unlikely. 
It means that we would theoretically expect a value that extreme or more extreme in only 5% of all cases.

## $\chi^2$

The $\chi^2$ Test for Independence determines if there is an association between **two categorical variables** in a contingency table.
To do so, it compares the observed frequencies in each category of that contingency table to the frequencies expected if the variables were independent.
For example, if there were no association (i.e. _statistical independence_) between gender and believing in the soul, then the proportion of men and women who believe in a soul should be about equal.

```{r echo = F}
addmargins(table(seminar$v01_gender, seminar$soul_dummy))
```

The test statistic $\chi^2$ is calculated as follows:

$$\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}$$

where 
    - \( O_i \) is the observed frequency in each category
    - \( E_i \) is the expected frequency in each category, calculated as: $$E_i = \frac{(row \ total) \times (column \ total)}{grand \ total}$$

The distribution of $\chi^2$ depends on the number of categories k or more precisely, the degrees of freedom, df. 
In a scenario where we have just one variable and we want to test empirical frequencies to expected ones, k is equal to the number of categories and df = k-1.
If we have two variables and we want to test their association as described above, k is not really relevant here and we focus on the degrees of freedom, calculated as df = (#rows - 1)x(#columns - 1).

![Chi squared distribution](./img/chidist.png)

### How to in R

In R, you calculated the $Chi^2$ test using the function `chisq.test()`, which only needs (categorical!) _x, y_ as input.
Here, we will look at the previous example of gender and soul belief and therefore add those two variables.
The function allows some other inputs as you can see in the example.
Especially with a small sample, we can add the input _simulate.p.value = T_, which bootstraps the analysis 2000 times to better estimate an accurate p-value.
    
```{r}
chisq.test(seminar$v01_gender, seminar$soul_dummy, simulate.p.value = T)
```

### Exercise <i class="fa-solid fa-ghost" style="color: #dcdcdc;"></i> <i class="fa-solid fa-music"></i>

We want to explore whether **belief in the soul (dummy)** is associated with **music preference**. 

Calculate a simple chisq.test and interpret the results.

`r hide("Solution <i class='fa-solid fa-ghost' style='color: #dcdcdc;'></i> <i class='fa-solid fa-music'></i>")`

```{r}
chisq.test(seminar$v07_genre, seminar$soul_dummy)
addmargins(table(seminar$v07_genre, seminar$soul_dummy))
```

`r unhide()` 

How would you interpret this result?

`r mcq(c("Dualists prefer Rock music.", "Music preferences influence the soul beliefs of a person.", answer = "There is no significant association between belief in the soul and music preference by genre.", "Chi squared is confusing."))`

## t-Test

As I've mentioned before, there is not really _the one_ t-test to rule them all.
Instead, the t-statistic which the t-tests are built around is calculated slightly differently depending on the actual situation.
There are three categories of t-test:

- **one-sample** t-test:
    - Test one sample against a known mean value
- **two-sample** t-test (independent):
    - Test two sample-means against each other (independent samples)
- **paired two-sample** t-test:
    - Test two dependent sample-means against each other (e.g. repeated measures)
    
### Test statistic _t_ 

The Test statistic T has a known distribution that depends on the **degrees of freedom df**, calculated as n-1.
It is similar to what we saw with the $\chi^2$ distribution but the t-distribution looks a lot more like the normal distribution.
Most (probable or to be expected) T values are around 0, so te further away or _more extreme_ the T value is from 0, the less likely it is caused by chance alone. $\rightarrow$ _significance_


![T distribution](./img/tdist.png)

It is calculated as follows:

- One sample: $$ t = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} $$

- Two sample: $$t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} $$

### How to in R

- The basic function is `t.test()` for any type of t.test
- One sample needs inputs _x, mu_ (if x is from a data set you should specify _data_)
- Two sample needs either
    - _x, y_ (if from data set, _data_) or
    - _x ~ group_ (if from data set, _data_)
- Paired test needs _paired = T_
- One-sided test needs _alternative = 'greater'_ (assumes first group mean to be larger than second; otherwise "less")

### Examples

**One sided - "greater" assumes that mean(x) is larger than mean(y)**

```{r}
t.test(x = 10:20, y = 0:10, alternative = "greater")
```

**Two sided using formula notation with the ~ tilde**

Does seminar motivation differ depending on the soul-belief of students?

```{r}
t.test(v10_motivation ~ soul_dummy, data = seminar)
```


### Exercise <i class="fa-solid fa-computer"></i> 

We want to test whether the **gender** stereotype that men are **more skilled with technology** appears in our seminar sample.

Perform a one-sided two-sample t-test and interpret the results.

_Hint: The grouping variable "v01_gender" is sorted alphabetically - so choose the "alternative" accordingly!_

`r hide("Solution <i class='fa-solid fa-computer'></i> ")`

```{r}
t.test(v05_skill_tech ~ v01_gender, data = seminar, alternative = "greater")
```

`r unhide()`

How would you interpret this result?

`r mcq(c(answer = "There are no significant gender differences in technological skill.", "Gender influences the thechnological skill of a person.", "Women have significantly more tech skills than men.", "T-Tests are confusing."))`


<!-- # ```{r} -->
<!-- # # remotes::install_github("tpepler/nonpar") -->
<!-- # nonpar::boot.t.test(seminar$v05_skill_tech[seminar$v01_gender == "man"],  -->
<!-- #                     seminar$v05_skill_tech[seminar$v01_gender == "woman"],  -->
<!-- #                     reps = 1000, -->
<!-- #                     alternative = "greater" -->
<!-- #                     ) -->
<!-- # ``` -->


## ANOVA

```{r anovaprince, echo = F, fig.cap="ANOVA principle"}
show_fig("./img/anova")
```


- Like a t-test for more than two groups
- Why do we not just calculate several t-tests?
    - $\alpha$ inflation! 
    - Significance level of 0.05 means that 1/20 tests will be significant by pure chance, so more tests makes it more likely that we hit that chance and make an alpha error (falsely reject null hypothesis)
  
### How to - theoretically

1.  Check Assumptions
    - Data should be normally distribution & variance in groups should be similar (homogeneous)
2. Sum of Squares: Sum of Squares total, within & between (_R does this for us_)
    - F-fraction as the measure of variance explained by the grouping variable in comparison to other variability in the dependent variable
3. Interpretation and post-hoc tests
    - If there are any significant differences at all, we can use pairwise t-tests (with alpha correction!)

### Example: Music genre and loudness <i class="fa-solid fa-music"></i> {-}

#### 1. Check assumptions {-}

- Check for Homogeneity of Variance with the Levene Test
- 
  ```{r}
  # Make sure the package "car" is installed first! If not, install.packages("car")
  # as.factor() forces R to recognize our group as such!
  car::leveneTest(v08_loudness ~ as.factor(v07_genre), data = seminar, center = mean)
  ```

- Interpretation?
    - p value < 0.05 would indicate significant differences in variance between the group, so we want it to be > 0.05
    - Assumption met! <i class="fa-regular fa-face-smile"></i>
    
#### 2. Define the overall model {-}

```{r genre-loud, message=FALSE}
model <- aov(v08_loudness ~ as.factor(v07_genre), data = seminar)
summary(model) # "Pr(>F)" is the p-value
```

- Interpretation?
    - Not significant (likely due to small sample size)
    - usually we would stop here then, but we will look at the post hoc tests anyway ;)
    
#### 3. Post Hoc Test {-}

```{r tukey}
TukeyHSD(model)
```

- Interpretation?
    - There are no significant pairwise differences in our (small) sample.

    
  - But we can simulate a larger sample (for fun)

### Addendum for demonstration only: Bootstrapped Data for larger sample size

```{r bs, message=FALSE}
data <- data.frame()

for(i in 1:10){
  boot <- seminar[sample(1:nrow(seminar), nrow(seminar), replace = T), ]
  data <- rbind(data, boot) # create many random samples from our data 
}

bootstrapped_model <- aov(v08_loudness ~ as.factor(v07_genre), data = data)
summary(bootstrapped_model)
TukeyHSD(bootstrapped_model)
```

Try to formulate a full interpretation of both the original as well as the bootstrapped data!
You can look at a suggestion below after you are done.

`r hide()`

"In our sample, ANOVA showed no significant differences between preferred music genre and preferred volume of listening to music (`r apa_print(model)$full_result |> suppressMessages()`). However, bootstrapping with 10 repetitions suggests that this lack of evidence might be due to the small sample size (`r apa_print(bootstrapped_model)$statistic |> suppressMessages()`), which is also supported by the large effect size (`r apa_print(bootstrapped_model)$estimate |> suppressMessages()`)."
 
`r unhide()`

### ANOVA Exercise

Reminder: There are generally 3 steps to an ANOVA

```{r loud-soul, eval = F}
car::leveneTest(v08_loudness ~ v11_soul, data = seminar) # 1.
model <- aov(v08_loudness ~ v11_soul, data = seminar) # 2.
summary(model)
TukeyHSD(model) # 3.
```


1. Check assumptions with Levene Test
2. Build the model to perform an omnibus ANOVA
3. Perform post-hoc tests to check pairwise differences (usually only if the omnibus ANOVA is significant)

### Exercise

**Does the preferred music volume depend on someone's soul philosophy?** <i class="fa-solid fa-music"></i><i class="fa-solid fa-ghost" style="color: #dcdcdc;"></i>

<br>

Perform an ANOVA on our seminar data to explore the question (v08 & v12). 

`r hide("Solution omnibus ANOVA")`

```{r leveneex}
car::leveneTest(v08_loudness ~ v12_soul_phil, data = seminar)
model <- aov(v08_loudness ~ v12_soul_phil, data = seminar)
summary(model)
```

`r unhide()`

<br>

Look for pairwise differences even if the overall ANOVA does not reach significance.

`r hide("Solution pairwise comparison")`

```{r tukeyex}
TukeyHSD(model)
```

`r unhide()`

<br>

Choose and create an appropriate visualization for this data!

`r hide("Solution Data Viz")`

```{r solvizanova, fig.height=4}
ggplot(seminar, aes(x = v12_soul_phil, y = v08_loudness, 
                    color = v12_soul_phil, fill = v12_soul_phil)) +
  geom_boxplot(alpha = .7) + 
  theme_minimal() + 
  theme(legend.position = "none") +
  labs(x = "Soul Philosophy", y = "Preferred Volume (arbitrary units)") +
  scale_color_brewer(palette = 4) + scale_fill_brewer(palette = 4)
```

`r unhide()`

## Wrap-Up & Further Resources {-}
 
<i class="fa-solid fa-anchor" style="color: teal;"></i>
<ul style="color: teal;"> 
<li>Chi$^2$ test measures association between two categorical variables </li>
<li>t Test measures differences between mean values (one sample, two sample, paired)</li>
<li>ANOVA can be thought of as an augmentation of the t test while controlling alpha inflation</li>
<li>Functions: chisq.test(), t.test(), aov()</li>
<li>Always try to imagine/ keep in mind what you might expect and _what the data would be like if that were true_</li>
<li>Read the documentation of each function for more options</li>
</ul>

<br>

<i class="fa-solid fa-book" style="color: orange;"></i>
<ul style="color: orange;">
<li> [Statistics Picker](https://the-tave.shinyapps.io/Statistik-Picker/){target="_blank"}</li>
<li> [Chi2-test (Statology)](https://www.statology.org/chi-square-test-of-independence-in-r/){target="_blank"} </li>
<li> [t-test (Statology)](https://www.statology.org/two-sample-t-test/){target="_blank"} </li>
<li> [ANOVA (Statology)](https://www.statology.org/interpret-anova-results-in-r/){target="_blank"} </li>
<li> _Discovering Statistics Using R_ [@field2012] </li>
</ul>

<!-- #id .class  -->
![Cute ANOVA curves](./img/sweet-anova.png){width=auto height=200px}
<figcaption style = "font-size: 7pt;">[https://www.pinterest.de/pin/59180182590147005/](https://www.pinterest.de/pin/59180182590147005/){target="_blank"}</figcaption>

